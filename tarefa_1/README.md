# ğŸš€ Cache e Acesso Ã  MemÃ³ria
Os processadores modernos possuem uma hierarquia de memÃ³ria para otimizar a velocidade de acesso aos dados:

Cache L1 (nÃ­vel 1): Pequena (32KBâ€“128KB por nÃºcleo), mas extremamente rÃ¡pida.

Cache L2 (nÃ­vel 2): Maior (256KBâ€“2MB por nÃºcleo), um pouco mais lenta que L1.

Cache L3 (nÃ­vel 3): Compartilhada entre os nÃºcleos, ainda maior, mas mais lenta que L2.

MemÃ³ria RAM: Muito maior (~GBs), mas muito mais lenta que as caches.

A ideia principal do cache Ã© armazenar dados frequentemente acessados para evitar leituras lentas da RAM. No entanto, quando os dados necessÃ¡rios nÃ£o estÃ£o no cache, ocorre um cache miss, e o processador precisa buscar os dados na RAM, o que Ã© centenas de vezes mais lento.

# ğŸ“Œ Por que a ordem de acesso (linha x coluna) importa?
A memÃ³ria RAM e os caches armazenam matrizes em ordem de linha (row-major order). Ou seja, uma matriz
ğ‘€
Ã—
ğ‘
MÃ—N Ã© armazenada como uma sequÃªncia de linhas contÃ­nuas na memÃ³ria.

##ğŸ”µ Acesso por Linhas (Row-Major Order)

```
for (int i = 0; i < size; i++) {
for (int j = 0; j < size; j++) {
result[i] += matrix[i][j] \* vector[j];
}
}
```

O acesso percorre a matriz linha a linha.

Como os elementos da mesma linha estÃ£o prÃ³ximos na memÃ³ria, eles sÃ£o carregados na cache de forma eficiente.

Poucos cache misses, pois o processador jÃ¡ preenche os blocos de cache com valores adjacentes.

# â¡ Resultado: Melhor uso da cache, execuÃ§Ã£o mais rÃ¡pida.

## ğŸ”´ Acesso por Colunas (Column-Major Order)

```
for (int j = 0; j < size; j++) {
for (int i = 0; i < size; i++) {
result[i] += matrix[i][j] \* vector[j];
}
}
```

O acesso percorre a matriz coluna por coluna.

Como os elementos da mesma coluna nÃ£o estÃ£o armazenados juntos na memÃ³ria, cada acesso a matrix[i][j] pode exigir um novo carregamento na cache, causando muitos cache misses.

Isso gera acessos frequentes Ã  memÃ³ria RAM, que Ã© muito mais lenta que a cache.

# â¡ Resultado: Desempenho degradado Ã  medida que o tamanho da matriz cresce.

ğŸ“Š O Impacto no Desempenho
Para matrizes pequenas, tudo cabe na cache L1 ou L2, entÃ£o a diferenÃ§a de tempo entre as abordagens Ã© pequena.

Para matrizes grandes (que ultrapassam a cache L1 e L2), a abordagem por colunas sofre penalizaÃ§Ãµes severas porque causa mais acessos Ã  RAM, que sÃ£o muito mais lentos.

O ponto exato onde a diferenÃ§a de tempo se torna significativa depende do tamanho do cache do processador em uso.

## ğŸ”¹ Exemplo prÃ¡tico:
Se sua CPU tiver uma cache L1 de 256KB e cada nÃºmero double ocupar 8 bytes, entÃ£o:

Uma matriz 200x200 ocupa 320KB (200Ã—200Ã—8 bytes), que jÃ¡ ultrapassa a cache L1.

Para 500x500 (2MB), jÃ¡ pode comeÃ§ar a ultrapassar atÃ© mesmo a cache L2.

# ğŸ”¥ Resumo
Acesso por linhas â†’ Melhor aproveitamento da cache â†’ Menos cache misses â†’ ExecuÃ§Ã£o mais rÃ¡pida.

Acesso por colunas â†’ Pior aproveitamento da cache â†’ Muitos cache misses â†’ Mais acessos Ã  RAM â†’ ExecuÃ§Ã£o mais lenta.

Quando a matriz cresce e ultrapassa o tamanho da cache L1/L2, a diferenÃ§a de tempo se torna evidente.
